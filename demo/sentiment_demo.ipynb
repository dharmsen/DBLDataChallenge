{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Standard dependencies\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Preprocessing\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Machine Learning\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from keras.models import load_model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDemo:\n",
    "    '''\n",
    "    Sentiment analysis \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.sentence = ''\n",
    "        self.stopwords = set(stopwords.words('english'))\n",
    "        self.stemmer = SnowballStemmer(\"english\")\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.nn_model = load_model('nn_sentiment_model.h5')\n",
    "        self.xgb_model = pickle.load(open('xgboost_1.dat', 'rb'))\n",
    "        self.mapping = {0 : 'Negative', 1 : 'Neutral', 2 : 'Positive'}\n",
    "        \n",
    "    def tokenize(self, sentence):\n",
    "        '''\n",
    "        Splits up words and makes a list of all words in the tweet\n",
    "        '''\n",
    "        tokenized_sentence = word_tokenize(sentence)\n",
    "        return tokenized_sentence\n",
    "            \n",
    "    def remove_stopwords(self, sentence):\n",
    "        '''Removes stopwords like 'a', 'the', 'and', etc.'''\n",
    "        filtered_sentence = []\n",
    "        for w in sentence:\n",
    "            if w not in self.stopwords and len(w) > 1 and w[:2] != '//' and w != 'https': \n",
    "                filtered_sentence.append(w)\n",
    "        return filtered_sentence\n",
    "    \n",
    "    def stem(self, sentence):\n",
    "        '''\n",
    "        Stems certain words to their root form.\n",
    "        For example, words like 'computer', 'computation'\n",
    "        all get trunacated to 'comput'\n",
    "        '''\n",
    "        return [self.stemmer.stem(word) for word in sentence]\n",
    "    \n",
    "    def join_to_string(self, sentence):\n",
    "        '''\n",
    "        Joins the tokenized words to one string.\n",
    "        '''\n",
    "        return ' '.join(sentence)\n",
    "    \n",
    "    def vectorize(self, sentence):\n",
    "        '''\n",
    "        Vectorizes a preprocessed sentence into a TF-IDF format\n",
    "        Returns a sparse matrix\n",
    "        '''\n",
    "        _ = self.vectorizer.fit_transform(np.load('vector.npy'))\n",
    "        return self.vectorizer.transform([sentence])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Makes predictions and maps the integer predictions to strings\n",
    "        '''\n",
    "        mapping = self.mapping\n",
    "        nn_prediction = mapping[np.argmax(self.nn_model.predict(X))]\n",
    "        xgb_prediction = mapping[int(self.xgb_model.predict(xgb.DMatrix(X)))]\n",
    "        return nn_prediction, xgb_prediction\n",
    "    \n",
    "    def preprocess(self):\n",
    "        '''\n",
    "        Preprocess a selected number of rows and\n",
    "        connects them back to strings\n",
    "        '''   \n",
    "        # Perform preprocessing\n",
    "        tweet = self.sentence\n",
    "        tokenized = self.tokenize(tweet)\n",
    "        cleaned = self.remove_stopwords(tokenized)\n",
    "        stemmed = self.stem(cleaned)\n",
    "        return self.join_to_string(stemmed)\n",
    "    \n",
    "    def demo(self):\n",
    "        '''\n",
    "        Asks for input and returns to \n",
    "        sentiment predictions as strings\n",
    "        '''\n",
    "        print('Please input your tweet\\n')\n",
    "        self.sentence = input()\n",
    "        print(f'\\nRetreiving predictions...')\n",
    "        # Preprocess, Vectorize and get predictions\n",
    "        processed = self.preprocess()\n",
    "        vectorized = self.vectorize(processed)\n",
    "        predictions = self.predict(vectorized)\n",
    "        print(f'\\nPrediction 1 (Neural Network): {predictions[0]}\\n\\nPrediction 2 (Gradient Boosting): {predictions[1]}')\n",
    "        # Return predictions as a tuple\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# Initialize demo\n",
    "Demo = SentimentDemo();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example tweets:\n",
    "\n",
    "### Positive:\n",
    "- Morning. Where is the best place to check if my flight tonight from Nice to Gatwick is running on time? Thanks.\n",
    "\n",
    "### Neutral:\n",
    "- I have a return ticket booked from lpl to egc. Is it a problem if I only use the return ticket?\n",
    "\n",
    "### Negative:\n",
    "- What an awful little old man at Fast Track International connections T5. Shouting, being horrible and giving wrong info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform sentiment prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can type anything you like and it will return two predictions. One is from a neural network model and one from a gradient boosting model. Both models have similar accuracy (Â± 80%), but only agree with each other around 85% of the time. Try it out by running the next cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input your tweet\n",
      "\n",
      "Morning. Where is the best place to check if my flight tonight from Nice to Gatwick is running on time? Thanks.\n",
      "\n",
      "Retreiving predictions...\n",
      "\n",
      "Prediction 1 (Neural Network): Positive\n",
      "\n",
      "Prediction 2 (XGBoost): Positive\n"
     ]
    }
   ],
   "source": [
    "# Perform demo\n",
    "Demo.demo();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input your tweet\n",
      "\n",
      "I have a return ticket booked from lpl to egc. Is it a problem if I only use the return ticket?\n",
      "\n",
      "Retreiving predictions...\n",
      "\n",
      "Prediction 1 (Neural Network): Neutral\n",
      "\n",
      "Prediction 2 (XGBoost): Neutral\n"
     ]
    }
   ],
   "source": [
    "# Perform demo\n",
    "Demo.demo();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input your tweet\n",
      "\n",
      "What an awful little old man at Fast Track International connections T5. Shouting, being horrible and giving wrong info.\n",
      "\n",
      "Retreiving predictions...\n",
      "\n",
      "Prediction 1 (Neural Network): Negative\n",
      "\n",
      "Prediction 2 (XGBoost): Negative\n"
     ]
    }
   ],
   "source": [
    "# Perform demo\n",
    "Demo.demo();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input your tweet\n",
      "\n",
      "Hello\n",
      "\n",
      "Retreiving predictions...\n",
      "\n",
      "Prediction 1 (Neural Network): Neutral\n",
      "\n",
      "Prediction 2 (XGBoost): Negative\n"
     ]
    }
   ],
   "source": [
    "# Perform demo\n",
    "Demo.demo();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
