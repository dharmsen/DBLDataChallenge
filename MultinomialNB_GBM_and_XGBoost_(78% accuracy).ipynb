{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('vader_lexicon')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics  import accuracy_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'airline_sentiment', 'airline_sentiment_confidence',\n",
       "       'negativereason', 'negativereason_confidence', 'airline',\n",
       "       'airline_sentiment_gold', 'name', 'negativereason_gold',\n",
       "       'retweet_count', 'text', 'tweet_coord', 'tweet_created',\n",
       "       'tweet_location', 'user_timezone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_csv('tweets.csv'); raw_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment\n",
       "0                @VirginAmerica What @dhepburn said.           neutral\n",
       "1  @VirginAmerica plus you've added commercials t...          positive\n",
       "2  @VirginAmerica I didn't today... Must mean I n...           neutral\n",
       "3  @VirginAmerica it's really aggressive to blast...          negative\n",
       "4  @VirginAmerica and it's a really big bad thing...          negative"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = raw_df[['text', 'airline_sentiment']]; df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14640</td>\n",
       "      <td>14640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>14427</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>@united thanks</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6</td>\n",
       "      <td>9178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  text airline_sentiment\n",
       "count            14640             14640\n",
       "unique           14427                 3\n",
       "top     @united thanks          negative\n",
       "freq                 6              9178"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11abc1668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['airline_sentiment'].value_counts().plot(kind='barh', \n",
    "                                            title='Target distribution');\n",
    "# Note: Dataset is biased toward negative tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessor:\n",
    "    def __init__(self, df):\n",
    "        self.data = df\n",
    "        self.conversations = self.data['text']\n",
    "        self.stopwords = set(stopwords.words('english'))\n",
    "        self.stemmer = SnowballStemmer(\"english\")\n",
    "        self.preprocessed = []\n",
    "        \n",
    "    def tokenize(self, sentence):\n",
    "        tokenized_sentence = word_tokenize(sentence)\n",
    "        return tokenized_sentence\n",
    "            \n",
    "    def remove_stopwords(self, sentence):\n",
    "        filtered_sentence = []\n",
    "        for w in sentence:\n",
    "            if w not in self.stopwords and len(w) > 1 and w[:2] != '//' and w != 'https': \n",
    "                filtered_sentence.append(w)\n",
    "        return filtered_sentence\n",
    "    \n",
    "    def stem(self, sentence):\n",
    "        return [self.stemmer.stem(word) for word in sentence]\n",
    "    \n",
    "    def join_to_string(self, sentence):\n",
    "        return ' '.join(sentence)\n",
    "    \n",
    "    def full_preprocess(self, n_rows):\n",
    "        for i in range(n_rows):\n",
    "            tweet = self.conversations[i]\n",
    "            tokenized = self.tokenize(tweet)\n",
    "            cleaned = self.remove_stopwords(tokenized)\n",
    "            stemmed = self.stem(cleaned)\n",
    "            joined = self.join_to_string(stemmed)\n",
    "            self.preprocessed.append(joined)\n",
    "            \n",
    "    def list_preprocess(self, n_rows):\n",
    "        for i in range(n_rows):\n",
    "            tweet = self.conversations[i]\n",
    "            tokenized = self.tokenize(tweet)\n",
    "            cleaned = self.remove_stopwords(tokenized)\n",
    "            stemmed = self.stem(cleaned)\n",
    "            self.preprocessed.append(stemmed)\n",
    "            \n",
    "    def get_data(self):\n",
    "        return self.preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "preprocessor = PreProcessor(df)\n",
    "preprocessor.full_preprocess(len(df))\n",
    "df['cleaned_text'] = preprocessor.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "#tokens = word_tokenize(df['text'].str.cat(sep=' '))\n",
    "#stop_words = set(stopwords.words('english'))\n",
    "#tokens = [w for w in tokens if not w in stop_words]\n",
    "#frequency_dist = nltk.FreqDist(tokens)\n",
    "#from wordcloud import WordCloud\n",
    "#wordcloud = WordCloud()\n",
    "#wordcloud.generate_from_frequencies(frequency_dist)\n",
    "#plt.imshow(wordcloud)\n",
    "#plt.axis(\"off\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation (to matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_text'], \n",
    "                                                    df['airline_sentiment'], \n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11712, 10085) (2928, 10085)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set (MultinomialNB): 73.096%\n",
      "Accuracy on test set (MultinomialNB): 68.2036%\n"
     ]
    }
   ],
   "source": [
    "train_pred = clf.predict(X_train)\n",
    "test_pred = clf.predict(X_test)\n",
    "print(f'Accuracy on training set (MultinomialNB): {round(accuracy_score(y_train, train_pred)*100, 4)}%')\n",
    "print(f'Accuracy on test set (MultinomialNB): {round(accuracy_score(y_test,test_pred)*100, 4)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn's Gradient Boosting Machine (GBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=6,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Untuned Gradient Boosting\n",
    "clf = GradientBoostingClassifier(n_estimators=200, \n",
    "                                 max_depth=6)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set (GBM little tuning): 87.1329%\n",
      "Accuracy on test set (GBM little tuning): 77.7322%\n"
     ]
    }
   ],
   "source": [
    "train_pred = clf.predict(X_train)\n",
    "test_pred = clf.predict(X_test)\n",
    "print(f'Accuracy on training set (GBM little tuning): {round(accuracy_score(y_train, train_pred)*100, 4)}%')\n",
    "print(f'Accuracy on test set (GBM little tuning): {round(accuracy_score(y_test,test_pred)*100, 4)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost (GBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {'objective' : 'multi:softmax',\n",
    "              'eval_metric' : 'mlogloss',\n",
    "              'eta' : 0.1,\n",
    "              'max_depth' : 6,\n",
    "              'num_class' : 3,\n",
    "              'lambda' : 0.8,\n",
    "              'estimators' : 200\n",
    "}\n",
    "\n",
    "target_train = y_train.astype('category').cat.codes\n",
    "target_test = y_test.astype('category').cat.codes\n",
    "\n",
    "d_train = xgb.DMatrix(X_train, label = target_train)\n",
    "d_test = xgb.DMatrix(X_test, label = target_test)\n",
    "\n",
    "watchlist = [(d_train, 'train'), (d_test, 'test')]\n",
    "\n",
    "# Fit XGBoost\n",
    "bst = xgb.train(xgb_params, \n",
    "                d_train, \n",
    "                400, \n",
    "                watchlist, \n",
    "                early_stopping_rounds = 50, \n",
    "                verbose_eval = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set (XGBoost little tuning): 88.9771%\n",
      "Accuracy on test set (XGBoost little tuning): 78.7568%\n"
     ]
    }
   ],
   "source": [
    "train_pred = bst.predict(d_train)\n",
    "test_pred = bst.predict(d_test)\n",
    "print(f'Accuracy on training set (XGBoost little tuning): {round(accuracy_score(target_train, train_pred)*100, 4)}%')\n",
    "print(f'Accuracy on test set (XGBoost little tuning): {round(accuracy_score(target_test, test_pred)*100, 4)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
